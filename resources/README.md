# Resources

This folder contains resources needed to run our pre-trained models.

The BERT language model used in our experiments is the
[BERT-Base Multilingual Cased](https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip)
model (without fine-tuning).
